# This `robots.txt` file is designed to tell web crawlers that we do not want them to crawl any pages on this website.
# Reference: https://developers.google.com/search/docs/crawling-indexing/robots/robots_txt
User-agent: *
Disallow: /
